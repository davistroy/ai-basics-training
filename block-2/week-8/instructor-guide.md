# **INSTRUCTOR GUIDE: BLOCK 2 WEEK 8**
## **Block 2 Capstone Evaluation**

**Block:** 2: AI Workflow Engineering
**Week:** 8 of 8
**Session Type:** Self-paced evaluation (no live workshop)
**Evaluation Duration:** 30-60 minutes per participant

---

## Quick Reference

| Element | Details |
|---------|---------|
| **Week Type** | Self-paced evaluation - no live workshop |
| **Session Focus** | Capstone submission and self-evaluation |
| **Difficulty Level** | N/A (evaluation week) |
| **Prep Time Required** | 30 minutes to review rubric and prepare feedback approach |
| **Demo Required** | No |
| **Common Challenges** | Honest self-assessment, incomplete submissions, documentation gaps |

---

## Navigation

**Block Navigation:** [<- Week 7 Instructor Guide](../week-7/instructor-guide.md) | **Week 8 (Final)** | [Block 3 Week 1 ->](../../block-3/week-1/instructor-guide.md)

**Related Materials:**
- [Week 8 Presentation](presentation.md) (Optional summary slides)
- [Week 8 Participant Guide](participant-guide.md)
- [Block 2 Main Document](../block-2.md)

---

## Week 8 Overview

Week 8 is a self-paced evaluation week with no live workshop. Participants complete their capstone submission and self-evaluation independently. The instructor's role shifts to review and certification.

### Week 8 Structure

| Day | Activity | Instructor Role |
|-----|----------|-----------------|
| Day 1-3 | Participants finalize submissions | Available for questions |
| Day 3-5 | Self-evaluations submitted | Monitor submissions |
| Day 5-7 | Instructor review | Review and certify |
| End of Week | Certification issued | Communicate results |

---

## Pre-Week Preparation

### 1 Week Before (During Week 7)

| Task | Details | Done? |
|------|---------|-------|
| Review rubric | Know all 8 criteria and scoring levels | |
| Prepare feedback templates | Have positive/constructive feedback ready | |
| Check participant status | Know who is on track, who needs support | |
| Set up submission process | Clear instructions for how to submit | |
| Block 3 enrollment info | Have ready for certified participants | |

### Beginning of Week 8

| Task | Details | Done? |
|------|---------|-------|
| Send week 8 announcement | Remind about submission deadlines | |
| Provide rubric | Ensure all have access to self-eval rubric | |
| Set office hours | Be available for final questions | |
| Monitor submissions | Track who has submitted | |

---

## Submission Requirements

### What Participants Submit

1. **GitHub Repository Link**
   - All workflow documentation
   - Prompt templates and rubrics
   - MCP configuration documentation
   - Performance logs/reports

2. **Impact Report**
   - `block-2-impact-report.md` with real data

3. **Capstone Summary**
   - `block-2-capstone-summary.md`

4. **Self-Evaluation (Optional but Encouraged)**
   - Completed rubric with scores
   - Evidence for each score
   - Reflection questions answered

### Submission Checklist

Verify each submission includes:

- [ ] GitHub repository link (accessible)
- [ ] 3 workflows documented
- [ ] Quality evaluation prompts included
- [ ] MCP configuration documented
- [ ] Performance logs present
- [ ] Impact report with actual data
- [ ] Capstone summary complete
- [ ] Self-evaluation (if provided)

---

## Evaluation Process

### Review Workflow

For each participant submission:

**Step 1: Initial Check (5 min)**
- Repository accessible?
- All required files present?
- Basic completeness verified?

**Step 2: Criterion Review (20 min)**
Review each of the 8 criteria:

| Criterion | What to Check |
|-----------|---------------|
| 1. Workflow Design | Architecture diagrams, error handling, efficiency |
| 2. Integration Quality | Tool connections, data flow documentation |
| 3. MCP Implementation | Config present, usage documented, practical application |
| 4. Quality Systems | Evaluation prompts, rubrics, routing logic |
| 5. Performance Monitoring | Logs present, metrics tracked, analysis done |
| 6. Documentation | Completeness, clarity, handoff-ready |
| 7. Practical Application | Real use cases, actual usage evidence |
| 8. Overall Value | Coherence, impact, professionalism |

**Step 3: Compare to Self-Evaluation (5 min)**
- If self-eval provided, compare your scores
- Note significant discrepancies
- Prepare feedback on self-assessment accuracy

**Step 4: Score and Document (5 min)**
- Finalize scores for each criterion
- Calculate total
- Prepare brief feedback

---

## Scoring Rubric Summary

### Criterion 1: Workflow Design (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | 3+ workflows, elegant architecture, comprehensive error handling, production-ready |
| 4 | 3 well-designed workflows, good architecture, solid error handling |
| 3 | 3 functional workflows, basic architecture, some error handling |
| 2 | <3 workflows or poorly designed, limited error handling |
| 1 | Incomplete or non-functional workflows |

### Criterion 2: Integration Quality (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Seamless multi-tool integration, clean data flow, handles edge cases |
| 4 | Good integration, minor data issues, generally reliable |
| 3 | Basic integrations working, some manual intervention needed |
| 2 | Limited integration, frequent issues, unreliable |
| 1 | No meaningful integration, constant failures |

### Criterion 3: MCP Implementation (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Multiple servers, GitHub integration, clear practical value, good security |
| 4 | 1-2 servers working, good practical use, reasonable documentation |
| 3 | Basic config, one server working, limited practical use |
| 2 | Limited success, configuration issues, minimal use |
| 1 | No MCP or non-functional |

### Criterion 4: Quality Systems (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Comprehensive system, automated evaluation, routing logic, feedback loop |
| 4 | Good system, automated evaluation, clear routing |
| 3 | Basic quality checks, some routing, review process exists |
| 2 | Minimal checking, poor routing, no systematic review |
| 1 | No quality system |

### Criterion 5: Performance Monitoring (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Comprehensive logging, metrics tracked, analysis performed, optimization evidence |
| 4 | Good logging, most metrics tracked, some analysis |
| 3 | Basic logging, some metrics, limited analysis |
| 2 | Minimal logging, few metrics, no analysis |
| 1 | No logging or tracking |

### Criterion 6: Documentation Completeness (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Comprehensive docs, architecture diagrams, setup guides, troubleshooting, examples |
| 4 | Good coverage, architecture documented, setup present |
| 3 | Basic docs, partially documented, incomplete setup |
| 2 | Minimal docs, missing architecture, incomplete |
| 1 | No documentation or unusable |

### Criterion 7: Practical Application (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Real needs addressed, 20+ executions, measurable time savings, high adoption potential |
| 4 | Relevant workflows, good usage, some savings, adoptable |
| 3 | Somewhat relevant, limited usage, theoretical value |
| 2 | Not clearly relevant, minimal usage, questionable value |
| 1 | No practical application |

### Criterion 8: Overall Toolkit Value (5 points)

| Score | Key Indicators |
|-------|----------------|
| 5 | Complete, coherent, significant impact, professional, exceeds requirements |
| 4 | All requirements met, components work together, good impact |
| 3 | Most requirements met, components function, some impact |
| 2 | Partially met, poor integration, limited impact |
| 1 | Major requirements missing, non-functional |

---

## Performance Levels

| Score Range | Level | Action |
|-------------|-------|--------|
| 34-40 | Excellent | Certify + celebrate |
| 28-33 | Good | Certify + minor feedback |
| 22-27 | Adequate | Certify + recommendations |
| 16-21 | Needs Improvement | Defer + specific guidance |
| 0-15 | Incomplete | Defer + required revisions |

### Certification Threshold

**22 points minimum** required for Block 2 certification.

Participants scoring below 22 should:
1. Receive specific feedback on gaps
2. Be given opportunity to revise
3. Resubmit for evaluation
4. Not proceed to Block 3 until certified

---

## Feedback Templates

### Excellent Performance (34-40)

```
Congratulations on an excellent Block 2 capstone! Your AI Workflow Toolkit demonstrates strong mastery of workflow automation, quality systems, and MCP integration.

Highlights:
- [Specific strength 1]
- [Specific strength 2]
- [Specific strength 3]

Your total score of [X]/40 places you in the Excellent category. You are certified as an AI Workflow Engineer and are ready for Block 3: AI Automation Architecture.

Next Steps:
- Block 3 enrollment: [Link/instructions]
- Start date: [Date]
```

### Good Performance (28-33)

```
Congratulations on completing Block 2! Your AI Workflow Toolkit shows solid competency in workflow automation and integration.

Strengths:
- [Specific strength 1]
- [Specific strength 2]

Areas for continued growth:
- [Specific area 1]
- [Specific area 2]

Your total score of [X]/40 places you in the Good category. You are certified as an AI Workflow Engineer and are ready for Block 3.

Consider addressing the growth areas above as you continue to Block 3.
```

### Adequate Performance (22-27)

```
Congratulations on completing Block 2. Your capstone meets the requirements for certification.

Strengths:
- [Specific strength]

Areas needing attention:
- [Specific gap 1]
- [Specific gap 2]
- [Specific gap 3]

Your total score of [X]/40 places you in the Adequate category. You are certified as an AI Workflow Engineer.

Before proceeding to Block 3, I recommend addressing:
- [Priority recommendation 1]
- [Priority recommendation 2]

This will strengthen your foundation for the more advanced Block 3 content.
```

### Needs Improvement (16-21)

```
Thank you for your Block 2 submission. While you've made good progress, there are some gaps that need to be addressed before certification.

Current strengths:
- [What they did well]

Areas requiring revision:
1. [Critical gap 1] - Currently scoring [X], needs [specific improvement]
2. [Critical gap 2] - Currently scoring [X], needs [specific improvement]
3. [Critical gap 3] - Currently scoring [X], needs [specific improvement]

Your current score of [X]/40 is below the 22-point certification threshold.

Next steps:
1. Review the feedback above
2. Make the specified improvements
3. Resubmit by [date]
4. I'm available for questions: [contact method]

You're close - let's get you over the finish line.
```

### Incomplete (0-15)

```
Thank you for your Block 2 submission. Significant work is still needed before certification.

Major gaps identified:
1. [Major gap 1]
2. [Major gap 2]
3. [Major gap 3]

Your current score of [X]/40 indicates that core Block 2 competencies have not yet been demonstrated.

Required next steps:
1. [Specific requirement 1]
2. [Specific requirement 2]
3. [Specific requirement 3]

I recommend we schedule a 1:1 session to discuss your path forward. Please reach out to arrange this.
```

---

## Self-Evaluation Calibration

### When Self-Eval Matches (within 3 points)

> "Your self-evaluation closely matches my assessment. This indicates strong self-awareness about your skills and work quality."

### When Self-Eval Is Lower Than Instructor

> "You scored yourself lower than my assessment. Be confident in your work - you achieved more than you gave yourself credit for. [Specific example of underrated area]."

### When Self-Eval Is Higher Than Instructor

> "Your self-evaluation was higher than my assessment in some areas. Let me explain the gap for [specific criterion]: [explanation of why score was lower]. This feedback is meant to help calibrate your self-assessment skills."

---

## Post-Evaluation Tasks

### Immediately After Evaluation

| Task | Done? |
|------|-------|
| Send feedback to each participant | |
| Issue certifications for 22+ scores | |
| Schedule follow-up for below-threshold | |
| Update tracking spreadsheet | |

### Within 48 Hours

| Task | Done? |
|------|-------|
| Provide Block 3 enrollment info to certified | |
| Answer any feedback questions | |
| Process any immediate resubmissions | |

### Within 1 Week

| Task | Done? |
|------|-------|
| Complete all evaluations | |
| All certifications issued | |
| Block 3 enrollment confirmed | |
| Block 2 retrospective notes captured | |

---

## Common Evaluation Challenges

### Challenge: Missing Documentation

**Signs:** Repository incomplete, links broken, files missing

**Response:**
- Note specific missing items
- Provide opportunity to complete
- Don't evaluate what's not there

### Challenge: Inflated Self-Evaluation

**Signs:** Self-scores much higher than evidence supports

**Response:**
- Be specific about evidence gaps
- Use examples from their work
- Frame as calibration opportunity

### Challenge: Good Work, Poor Documentation

**Signs:** Workflows function but aren't documented

**Response:**
- Acknowledge the working system
- Emphasize documentation is part of deliverable
- May affect Documentation criterion significantly

### Challenge: Late Submission

**Response:**
- Evaluate if possible within timeframe
- Note lateness in feedback
- Don't penalize score for timing

---

## Certification Process

### For Certified Participants (22+)

1. **Send certification message** with score and feedback
2. **Provide Block 3 info**:
   - Enrollment link/instructions
   - Start date
   - Prerequisites review
3. **Update tracking** to show certification status
4. **Celebrate** their achievement

### For Deferred Participants (<22)

1. **Send detailed feedback** with specific gaps
2. **Provide revision deadline** (typically 1 week)
3. **Offer support** for addressing gaps
4. **Re-evaluate** upon resubmission

---

## Block 2 Completion Notes

### What Certified Participants Have Demonstrated

- Ability to design and build multi-step AI workflows
- Proficiency in MCP configuration and tool integration
- Understanding of quality systems and automated evaluation
- Skill in performance monitoring and optimization
- Creation of reusable workflow templates
- Measured business impact with actual data

### Certification Title

**AI Workflow Engineer** (Block 2 Certified)

### Transition to Block 3

Block 3 (AI Automation Architecture) builds on Block 2:
- Workflows become agent building blocks
- MCP becomes agent tool access
- Quality systems become agent guardrails
- Monitoring becomes agent supervision

---

## Quick Reference Cards

### Key Messages for Feedback

1. "Your work demonstrates [specific competency]"
2. "This area could be strengthened by [specific action]"
3. "Block 3 will build on [specific skill they've shown]"

### Evaluation Efficiency Tips

1. Use the submission checklist first to catch incomplete work
2. Score each criterion as you review, don't defer
3. Write feedback notes as you go
4. Compare to self-eval at the end

### If You Only Have Time For One Thing

Focus on Overall Toolkit Value (Criterion 8) - it captures the holistic assessment.

---

**Navigation:** [<- Week 7 Instructor Guide](../week-7/instructor-guide.md) | **Week 8 (Final)** | [Block 3 Week 1 ->](../../block-3/week-1/instructor-guide.md)
