# **PRESENTATION: BLOCK 2 WEEK 7**
## **Block 2 Capstone Preparation**

**Block:** 2: AI Workflow Engineering
**Week:** 7 of 8
**Duration:** 45 minutes
**Theme Color:** Orange (Block 2)

**Key Thesis:** Real execution data transforms workflows from promising prototypes into proven business cases with quantifiable ROI, while comprehensive documentation ensures sustainable impact beyond individual creators.

---

## Slide Overview

| Slide # | Title | Duration | Type |
|---------|-------|----------|------|
| 1 | Title Slide | 0:30 | Title |
| 2 | Week 7 Learning Objectives | 1:00 | Overview |
| 3 | Where We Are in Block 2 | 1:30 | Context |
| 4 | Capstone: Required Components | 3:00 | Requirements |
| 5 | Capstone: Evaluation Criteria | 3:00 | Requirements |
| 6 | Scoring Guide | 2:00 | Requirements |
| 7 | Self-Evaluation Preview | 2:00 | Requirements |
| 8 | Why Real Data Matters | 2:00 | Concept |
| 9 | Data to Collect | 2:30 | Technical |
| 10 | Impact Calculation Walkthrough | 5:00 | Demo |
| 11 | Annual Projection | 3:00 | Calculation |
| 12 | Workflow Documentation Checklist | 3:00 | Checklist |
| 13 | Quality System Documentation | 2:00 | Checklist |
| 14 | MCP Documentation | 2:00 | Checklist |
| 15 | The Documentation Test | 2:00 | Concept |
| 16 | Block 3 Preview | 3:00 | Preview |
| 17 | Prerequisites for Block 3 | 2:00 | Preview |
| 18 | This Week's Exercises | 2:00 | Assignment |
| 19 | Week 8 Preview | 1:30 | Preview |
| 20 | Q&A | - | Interactive |

---

## Slide 1: Title Slide

### Block 2 Capstone Preparation
#### Finalizing Your AI Workflow Toolkit

**Block 2: AI Workflow Engineering**
Week 7 of 8

*[Company/Training Logo]*

**Speaker Notes:**
Welcome to Week 7 - Capstone Preparation. We're in the home stretch. You've built workflows, quality systems, MCP integration. Today we finalize everything for evaluation. We'll review requirements, calculate real impact, and prepare your portfolio. Next week is evaluation week.

---

## Slide 2: Week 7 Learning Objectives

### By the End of This Session, You Will:

1. **Know** all capstone requirements and evaluation criteria
2. **Calculate** real ROI from your workflow executions
3. **Prepare** complete documentation for your portfolio
4. **Understand** what comes in Block 3
5. **Be Ready** for self-evaluation next week

**Speaker Notes:**
These objectives are about synthesis and preparation. No new concepts today - we're bringing everything together. By the end of homework, your capstone should be complete and ready for Week 8 evaluation.

---

## Slide 3: Where We Are in Block 2

### Block 2 Journey

| Week | Focus | Status |
|------|-------|--------|
| Week 1 | Automation Platforms | Complete |
| Week 2 | First Workflow | Complete |
| Week 3 | Quality Systems | Complete |
| Week 4 | Optimization | Complete |
| Week 5 | MCP Integration | Complete |
| Week 6 | Integration Patterns | Complete |
| **Week 7** | **Capstone Prep** | **TODAY** |
| Week 8 | Capstone Evaluation | Next Week |

**Speaker Notes:**
Quick status check: Who has all three workflows working? [Count] Who has at least two? [Count] Who needs support? [Note names] If you're behind, that's your homework priority. We need everything ready for Week 8.

---

## Slide 4: Capstone Required Components

### 5 Required Deliverables

| Component | Description | Location |
|-----------|-------------|----------|
| **3 Workflow Templates** | Documented, tested, integrated | Automation platform |
| **Quality System** | Evaluation prompts, rubrics, gates | GitHub repo |
| **MCP Demonstration** | Functional integration | Claude Desktop |
| **Performance Docs** | Metrics, logs, analysis | GitHub repo |
| **Impact Measurement** | Real data, ROI calculation | Impact report |

### The Complete Package
Your capstone is a professional AI workflow toolkit that others could adopt.

**Speaker Notes:**
These five components make up your capstone. Think of it as a professional toolkit you could hand to a colleague. Workflows do the work. Quality system ensures standards. MCP enables tools. Performance docs show it works. Impact measurement proves the value.

---

## Slide 5: Capstone Evaluation Criteria

### 8 Dimensions, 40 Points Maximum

| # | Criterion | What's Evaluated | Points |
|---|-----------|------------------|--------|
| 1 | Workflow Design | Architecture, error handling, efficiency | /5 |
| 2 | Integration Quality | Component connections, data flow | /5 |
| 3 | MCP Implementation | Functional use, configuration | /5 |
| 4 | Quality Systems | LLM-as-judge, rubrics, gates | /5 |
| 5 | Performance Monitoring | Logging, metrics, analysis | /5 |
| 6 | Documentation | All required docs present, clear | /5 |
| 7 | Practical Application | Real use cases addressed | /5 |
| 8 | Overall Toolkit Value | Holistic assessment | /5 |

**Speaker Notes:**
You'll be evaluated on eight dimensions. Each is worth 5 points, for 40 total. Notice these cover technical quality, documentation, and practical value. You'll score yourself on all eight next week. Honest self-assessment is the goal.

---

## Slide 6: Scoring Guide

### How Scores Translate

| Score Range | Level | Meaning |
|-------------|-------|---------|
| **32-40** | Excellent | Strong mastery, ready for Block 3 |
| **28-31** | Proficient | Solid competency, minor gaps |
| **24-27** | Developing | Meets requirements, room to grow |
| **Below 24** | Needs Work | Additional development required |

### Per-Criterion Scoring

| Score | Description |
|-------|-------------|
| 5 | Exceptional - Exceeds expectations |
| 4 | Strong - Meets all requirements well |
| 3 | Adequate - Meets basic requirements |
| 2 | Developing - Partial completion |
| 1 | Beginning - Minimal evidence |

**Speaker Notes:**
These thresholds guide your self-evaluation. Be honest. A 3 means you met requirements - that's not bad. A 5 means you exceeded expectations. Most people land in the 28-35 range. The goal is accurate self-assessment, not maximum scores.

---

## Slide 7: Self-Evaluation Preview

### Week 8 Process

1. **Score yourself** on all 8 criteria
2. **Provide evidence** for each score
3. **Reflect** on your learning journey
4. **Identify** areas for continued growth
5. **Plan** for Block 3

### Evidence Examples

| Criterion | Evidence Type |
|-----------|---------------|
| Workflow Design | Screenshot + architecture diagram |
| Integration Quality | Data flow documentation |
| MCP Implementation | Configuration file + usage example |
| Quality Systems | Rubric + sample evaluation |
| Performance | Execution logs + metrics |
| Documentation | Complete repo contents |
| Practical Application | Real use case description |
| Overall Value | Impact report summary |

**Speaker Notes:**
Next week you'll score yourself. Each score needs evidence - don't just claim a 5, show why it's a 5. This is professional self-assessment. It's a skill you'll use throughout your career. Come prepared with links and examples.

---

## Slide 8: Why Real Data Matters

### Projections vs. Actuals

| Projections | Actuals |
|-------------|---------|
| "Could save 10 hours/month" | "Saved 16.7 hours this month" |
| "Might improve quality" | "Quality scores average 4.2/5" |
| "Should have good ROI" | "Achieved 71,000% ROI" |

### Real Data Tells the Story

- **Stakeholders trust numbers** over estimates
- **You can learn** from actual performance
- **Future projections** are more credible with a baseline
- **Your business case** becomes undeniable

**Speaker Notes:**
Real data is your superpower. When you tell your manager "I saved 16 hours and it cost $3.50," that's a story they remember. Projections are ignored. Actuals get attention. This is the skill that justifies AI investment.

---

## Slide 9: Data to Collect

### From Your Automation Platform

| Data Point | Where to Find |
|------------|---------------|
| Total executions | Execution history |
| Execution timestamps | Execution logs |
| Duration per execution | Execution details |
| Success/failure rates | Status counts |
| Error details | Failed execution logs |

### From Your Quality System

| Data Point | Where to Find |
|------------|---------------|
| Quality scores | Evaluation outputs |
| Pass rates | Router metrics |
| Review rates | Review queue |
| Revision rates | Tracked revisions |

### From Block 1

| Data Point | Purpose |
|------------|---------|
| Manual process time | Baseline for comparison |
| Previous quality level | Quality improvement measure |

**Speaker Notes:**
Pull this data before you start calculations. Execution history in Make or n8n has most of what you need. Quality scores may be in your logs or router. Block 1 baseline is from your memory or records - estimate if needed, but document your estimation method.

---

## Slide 10: Impact Calculation Walkthrough

### Live Calculation Example

**Time Savings:**
```
Manual process time: 45 minutes
Automated process time: 5 minutes
Savings per execution: 40 minutes
Number of executions: 25
Total time saved: 25 x 40 = 1000 min = 16.7 hours
```

**Cost Analysis:**
```
AI API costs: $3.50
Platform costs: $0.00 (free tier)
Total cost: $3.50
```

**ROI Calculation:**
```
Time saved: 16.7 hours
Value at $150/hr: $2,505
Cost: $3.50
Net value: $2,501.50
ROI: $2,501.50 / $3.50 = 71,471%
```

**Speaker Notes:**
[Walk through this calculation live with actual or realistic numbers.] Notice we're using real execution data, not projections. The ROI looks massive because knowledge work is expensive and AI is cheap. Even with smaller numbers, you'll see significant ROI.

---

## Slide 11: Annual Projection

### Scaling Your Impact

**From Actual to Annual:**
```
Current weekly rate: 6 executions
Annual executions: 6 x 52 = 312
Annual time saved: 312 x 40 min = 208 hours
Annual value: 208 x $150 = $31,200
Annual cost: $3.50 x 12 = $42
Annual net value: $31,158
```

**Team Scale Potential:**
```
Team size: 5 people
Team annual value: $31,158 x 5 = $155,790
```

### The Business Case Writes Itself

When you can show $31K annual value for $42 cost, approvals are easy.

**Speaker Notes:**
Annual projections are credible when based on actual data. Note we're multiplying your real weekly rate, not an optimistic guess. Team scale shows the potential. This is how you justify AI investments to leadership.

---

## Slide 12: Workflow Documentation Checklist

### For Each Workflow (3 total)

| Document | Purpose | Complete? |
|----------|---------|-----------|
| Architecture diagram | Visual overview | |
| Configuration guide | How to set up | |
| Integration dependencies | What's required | |
| Troubleshooting guide | How to fix issues | |
| Performance benchmarks | Expected metrics | |
| Example executions | Sample outputs | |

### The Handoff Test

> "Could someone else set up and maintain this workflow based on your documentation alone?"

If yes, you're done. If no, add more detail.

**Speaker Notes:**
Each workflow needs complete documentation. The handoff test is your quality check. If your documentation fails the handoff test, you own the workflow forever. Good documentation means freedom.

---

## Slide 13: Quality System Documentation

### Quality Components

| Document | Contents | Complete? |
|----------|----------|-----------|
| Evaluation prompts | All prompts used for evaluation | |
| Quality rubrics | Scoring criteria for each workflow | |
| Routing logic | How scores determine next steps | |
| Human review process | Queue, interface, feedback loop | |

### Organization Suggestion

```
/quality-system/
  /prompts/
    evaluation-wf1.md
    evaluation-wf2.md
    evaluation-wf3.md
  /rubrics/
    rubric-wf1.md
    rubric-wf2.md
    rubric-wf3.md
  routing-logic.md
  human-review-process.md
```

**Speaker Notes:**
Your quality system documentation proves you built systematic evaluation, not just one-off checks. Include all prompts, rubrics, and the routing logic. This is what makes your workflows production-grade.

---

## Slide 14: MCP Documentation

### MCP Configuration

| Document | Contents | Complete? |
|----------|----------|-----------|
| Configuration file | Sanitized config (no tokens) | |
| Setup instructions | How to configure | |
| Usage examples | How to use in practice | |
| Security notes | Token management, permissions | |

### Example Structure

```markdown
# MCP Configuration Guide

## Prerequisites
- Claude Desktop installed
- Node.js installed
- GitHub account with token

## Configuration File
Location: [path]
\`\`\`json
{
  "mcpServers": {
    "filesystem": { ... },
    "github": { ... }
  }
}
\`\`\`

## Usage Examples
- Reading templates: "Read my prompt template from GitHub"
- Accessing files: "List files in my prompts directory"
```

**Speaker Notes:**
MCP documentation shows you can configure AI tools, not just use them. Sanitize the config - remove actual tokens. Focus on explaining how someone else could replicate your setup.

---

## Slide 15: The Documentation Test

### Three Questions

1. **Setup:** Could someone else configure your system?
2. **Usage:** Could someone else run your workflows?
3. **Maintenance:** Could someone else fix issues?

### If Any Answer Is "No"

Add more documentation to that area:
- More screenshots
- More step-by-step instructions
- More troubleshooting tips
- More examples

### The Standard

> "If I go on vacation (or leave the company), could a colleague take over?"

**Speaker Notes:**
Apply these three questions to every component. Setup, usage, maintenance. Documentation that fails any of these tests is incomplete. This isn't busywork - it's professional responsibility. Well-documented work has lasting impact.

---

## Slide 16: Block 3 Preview

### Block 3: AI Automation Architecture

**What You'll Build:**
- Reliable AI agents with guardrails
- Multi-agent orchestration patterns
- Production deployment systems
- Team-scale AI workflows

**The Progression:**
- Block 1: Prompt engineering (the brain)
- Block 2: Workflow automation (the body)
- Block 3: Agent architecture (autonomous systems)

### Your Workflows Become Building Blocks

The workflows you built in Block 2 become components that agents orchestrate in Block 3.

**Speaker Notes:**
Block 3 takes everything you've built and makes it autonomous. Your workflows become the building blocks that agents coordinate. MCP becomes how agents access tools. Quality systems become agent guardrails. Everything connects.

---

## Slide 17: Prerequisites for Block 3

### Required to Enroll

| Prerequisite | What It Means |
|--------------|---------------|
| Block 2 completion | Capstone submitted and evaluated |
| Strong workflow foundation | 3 working workflows |
| MCP proficiency | Configured and functional |
| Quality system thinking | LLM-as-judge implemented |

### What You're Bringing to Block 3

- Experience building automation
- Understanding of quality gates
- MCP configuration skills
- Documentation practice
- Impact measurement ability

### Enrollment Information

[Share timing, registration details, contact]

**Speaker Notes:**
Block 3 requires Block 2 completion - that's why we're finalizing your capstone now. Everything you've built carries forward. The skills become prerequisites. If you're interested in Block 3, complete your capstone well.

---

## Slide 18: This Week's Exercises

### Homework (60 minutes minimum)

**Exercise 7.1: Finalize All Workflows (Variable)**
- Review each workflow against requirements
- Run 3+ final tests per workflow
- Polish all documentation
- Deliverable: 3 finalized workflows

**Exercise 7.2: Calculate Real Impact (25 min)**
- Export execution data
- Calculate actual metrics
- Create impact report
- Deliverable: `block-2-impact-report.md`

**Exercise 7.3: Create Capstone Summary (10 min)**
- Document all components
- Link everything together
- Deliverable: `block-2-capstone-summary.md`

**Speaker Notes:**
This homework is about completion, not learning. Exercise 7.1 may take longer if you have gaps to fill. Do it. The impact report in 7.2 is your business case. The summary in 7.3 ties everything together. Spend what time you need.

---

## Slide 19: Week 8 Preview

### Capstone Evaluation Week

**What Happens:**
- Self-evaluation on all 8 criteria
- Evidence documentation
- Reflection on learning journey
- Block 3 planning

**What to Prepare:**
- Complete capstone (all components)
- Evidence for each evaluation criterion
- Honest self-assessment mindset
- Thoughts on Block 3 goals

### No New Exercises

Week 8 is evaluation only. All work should be complete.

**Speaker Notes:**
Week 8 is the finish line. No new exercises - just evaluation. Come with your complete capstone and evidence for self-assessment. Be honest in your scoring. This is about learning, not grades.

---

## Slide 20: Q&A

### Questions?

**Common Questions:**

- "What if I don't have enough executions?"
  - Use what you have. Even 10 is valuable data.

- "How honest should self-evaluation be?"
  - Completely. Evidence should support scores.

- "What if one workflow isn't working?"
  - Quality over quantity. Two excellent beats three incomplete.

**Resources:**
- Capstone rubric (provided)
- Impact report template (participant guide)
- Documentation examples (GitHub)

**Next Week:** Capstone Evaluation

**Speaker Notes:**
Take questions. Common concerns: not enough data (use what you have), self-evaluation honesty (be accurate), incomplete work (quality over quantity). Emphasize that support is available - reach out now, not next week.

---

## Appendix: Impact Report Template

### Quick Reference

```markdown
# Block 2 Impact Report

## Execution Summary
- Total executions: [N]
- Success rate: [X]%

## Time Savings
| Workflow | Manual | Automated | Saved | Count | Total |
|----------|--------|-----------|-------|-------|-------|
| WF1 | X min | X min | X min | N | X hr |
| WF2 | | | | | |
| WF3 | | | | | |
| **Total** | | | | | **X hr** |

## Cost Analysis
- AI costs: $X
- Platform costs: $X
- **Total cost:** $X
- **Value created:** $X
- **ROI:** X%

## Annual Projection
- Annual value: $X
- Annual cost: $X
- **Net annual ROI:** $X
```

---

## Appendix: Capstone Summary Template

### Quick Reference

```markdown
# Block 2 Capstone Summary

## Participant: [Name]
## Date: [Date]

### Workflows
1. [Name] - [Purpose] - [Link]
2. [Name] - [Purpose] - [Link]
3. [Name] - [Purpose] - [Link]

### Quality System
- [Description] - [Link]

### MCP Implementation
- [Description] - [Link]

### Impact Summary
- Time saved: X hours
- ROI: X%
- Annual projection: $X

### Repository: [URL]
```

---

## Appendices

**Slide Type Definitions:** TITLE SLIDE | PROBLEM STATEMENT | INSIGHT / REVELATION | CONCEPT INTRODUCTION | FRAMEWORK / MODEL | COMPARISON | DEEP DIVE | CASE STUDY | PATTERN / BEST PRACTICE | METRICS / DATA | ARCHITECTURE / DIAGRAM | OBJECTION HANDLING | ACTION / NEXT STEPS | SUMMARY / RECAP | SECTION DIVIDER | CLOSING / CALL TO ACTION | Q&A / CONTACT

**Content Guidelines:** Use parallel structure in bullets | Clear tables with headers | Bad/Good example contrasts | Key principle callouts | Stage directions in speaker notes `[Pause]` `[Point to X]` `[Emphasize]`

**Block 2 Orange Theme:** Primary Orange (#FF6B35) for branding | Accent blues/grays | Orange highlights for emphasis | Consistent color across all Block 2 presentations

**Quality Checklist:** Learning objectives align | Key Thesis clear | Complete speaker notes | Technical accuracy | Relevant examples | Research citations specific | Q&A addresses objections | Orange theme consistent | Progressive building | Realistic timing

---

## Version History

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 1.0 | 2025-01-01 | Initial presentation created | Training Team |
| 2.0 | 2026-01-03 | Enhanced with comprehensive slide structure, BACKGROUND sections, Sources, Implementation Guidance, and expanded appendices | Claude |

---

**Navigation:** [<- Week 6 Presentation](../week-6/presentation.md) | **Week 7** | [Week 8 Presentation ->](../week-8/presentation.md)
