# **PARTICIPANT GUIDE: BLOCK 2 WEEK 7**
## **Block 2 Capstone Preparation**

**Block:** 2: AI Workflow Engineering
**Week:** 7 of 8
**Self-Study Time:** 60 minutes (minimum)
**Theme Color:** Orange (Block 2)

---

## Navigation

**Block Navigation:** [<- Week 6 Participant Guide](../week-6/participant-guide.md) | **Week 7** | [Week 8 Participant Guide ->](../week-8/participant-guide.md)

**Related Materials:**
- [Week 7 Presentation](presentation.md)
- [Week 7 Instructor Guide](instructor-guide.md)
- [Block 2 Main Document](../block-2.md)

---

## Introduction

### What You'll Learn This Week

This week focuses on preparing your Block 2 capstone for evaluation. You'll review all requirements, calculate real impact from your workflows, and prepare your portfolio documentation. This is a synthesis week - no new concepts, just bringing everything together.

### Prerequisites Checklist

Before starting this week's exercises, ensure you have:

- [ ] 3 working, integrated workflows
- [ ] MCP configured and functional
- [ ] Quality systems implemented
- [ ] 20+ logged workflow executions (ideally)
- [ ] Performance metrics tracked

### Materials Needed

| Item | Purpose | Where to Get |
|------|---------|--------------|
| Execution logs | Impact calculation | Automation platform |
| Block 1 baseline | Comparison metrics | Your Block 1 records |
| All workflow documentation | Portfolio preparation | Your GitHub repo |
| Capstone rubric | Self-evaluation prep | Provided in session |

---

## Session Content Summary

### Key Concepts Covered

#### 1. Capstone Requirements

**Required Components (5 deliverables):**

| Component | Description | Where |
|-----------|-------------|-------|
| 3 Workflow Templates | Documented, tested, integrated | Automation platform |
| Quality System | Evaluation prompts, rubrics, gates | GitHub repo |
| MCP Demonstration | Functional integration | Claude Desktop |
| Performance Documentation | Metrics, logs, analysis | GitHub repo |
| Impact Measurement | Real data, ROI calculation | Impact report |

**Evaluation Criteria (8 dimensions, 5 points each = 40 total):**

| Criterion | What's Evaluated | Points |
|-----------|------------------|--------|
| 1. Workflow Design | Architecture, error handling, efficiency | /5 |
| 2. Integration Quality | Component connections, data flow | /5 |
| 3. MCP Implementation | Functional use, configuration | /5 |
| 4. Quality Systems | LLM-as-judge, rubrics, gates | /5 |
| 5. Performance Monitoring | Logging, metrics, analysis | /5 |
| 6. Documentation Completeness | All required docs present | /5 |
| 7. Practical Application | Real use cases addressed | /5 |
| 8. Overall Toolkit Value | Holistic assessment | /5 |

**Scoring Guide:**
- 32-40: Excellent - Strong mastery
- 28-31: Proficient - Solid competency
- 24-27: Developing - Meets requirements
- <24: Needs work - Additional development required

#### 2. Impact Measurement Framework

**Time Savings Calculation:**
```
Manual process time (Block 1): X minutes/execution
Automated process time (Block 2): Y minutes/execution
Savings per execution: X - Y = Z minutes
Total executions: N
Total time saved: Z x N = hours
```

**Quality Improvement:**
```
Average quality score: X.X/5
Pass rate (auto-approved): X%
Review rate: X%
Revision rate: X%
```

**Cost Analysis:**
```
AI API costs: $X
Platform costs: $X
Total automation cost: $X
Value of time saved: hours x rate = $X
Net ROI: Value - Costs = $X
ROI percentage: (Value - Cost) / Cost x 100 = X%
```

**Annual Projection:**
```
Weekly execution rate: X
Annual executions: X x 52 = N
Annual time saved: N x savings/exec = hours
Annual value: hours x rate = $X
Team scale: value x team size = $X
```

#### 3. Portfolio Preparation

**Workflow Documentation Checklist (per workflow):**
- [ ] Architecture diagram
- [ ] Step-by-step configuration guide
- [ ] Integration dependencies listed
- [ ] Troubleshooting guide
- [ ] Performance benchmarks
- [ ] Example executions

**Quality System Documentation:**
- [ ] All evaluation prompts
- [ ] Rubrics for each workflow
- [ ] Quality routing logic
- [ ] Human review process

**MCP Documentation:**
- [ ] Configuration file (sanitized)
- [ ] Server setup instructions
- [ ] Usage examples
- [ ] Security notes

#### 4. Block 3 Preview

**Block 3: AI Automation Architecture**
- Building reliable AI agents
- Multi-agent orchestration
- Production deployment patterns
- Team scaling strategies

**Prerequisites for Block 3:**
- Block 2 completion
- Strong workflow foundation
- MCP proficiency
- Quality system thinking

---

## Self-Paced Exercises

### Exercise 7.1: Finalize All Workflows (Variable time - as needed)

**Objective:** Complete and polish your entire workflow toolkit

**Part 1: Workflow Review Checklist**

For each workflow, verify:

**Workflow 1: [Name]**
- [ ] Fully functional end-to-end
- [ ] Error handling implemented
- [ ] Quality check integrated
- [ ] Logging active
- [ ] MCP integration (if applicable)
- [ ] Documentation complete

**Workflow 2: [Name]**
- [ ] Fully functional end-to-end
- [ ] Error handling implemented
- [ ] Quality check integrated
- [ ] Logging active
- [ ] MCP integration (if applicable)
- [ ] Documentation complete

**Workflow 3: [Name]**
- [ ] Fully functional end-to-end
- [ ] Error handling implemented
- [ ] Quality check integrated
- [ ] Logging active
- [ ] MCP integration (at least one workflow)
- [ ] Documentation complete

**Part 2: Final Testing**

Run 3+ executions per workflow and document results:

**Workflow 1 Test Results:**
| Test | Input | Expected | Actual | Pass? |
|------|-------|----------|--------|-------|
| 1 | | | | |
| 2 | | | | |
| 3 | | | | |

**Workflow 2 Test Results:**
| Test | Input | Expected | Actual | Pass? |
|------|-------|----------|--------|-------|
| 1 | | | | |
| 2 | | | | |
| 3 | | | | |

**Workflow 3 Test Results:**
| Test | Input | Expected | Actual | Pass? |
|------|-------|----------|--------|-------|
| 1 | | | | |
| 2 | | | | |
| 3 | | | | |

**Part 3: Documentation Polish**

Ensure each workflow has:
1. Clear architecture diagram (draw.io or similar)
2. Step-by-step setup guide
3. Troubleshooting section
4. Version history

**Deliverables:**
- [ ] 3 finalized workflows, all tests passing
- [ ] Complete documentation for each workflow
- [ ] All materials committed to GitHub

---

### Exercise 7.2: Calculate Real Impact (25 minutes)

**Objective:** Document actual business value with real data

**Part 1: Export Execution Data (5 min)**

From your automation platform, gather:
- Total execution count
- Date range
- Execution durations
- Success/failure rates
- Quality scores (if logged)
- Any error data

**Part 2: Create Impact Report (20 min)**

Create `block-2-impact-report.md` in your repository:

```markdown
# Block 2 Impact Report

## Overview
- **Participant:** [Your name]
- **Report Date:** [Date]
- **Block 2 Period:** [Start date] to [End date]

---

## Execution Summary

| Metric | Value |
|--------|-------|
| Total workflow executions | [N] |
| Workflows in production | 3 |
| Date range | [Start] to [End] |
| Success rate | [X]% |

---

## Time Savings Analysis

### Baseline (Block 1 / Manual Process)

| Task | Manual Time | Notes |
|------|-------------|-------|
| [Task 1 - related to WF1] | X min | [How measured/estimated] |
| [Task 2 - related to WF2] | X min | [How measured/estimated] |
| [Task 3 - related to WF3] | X min | [How measured/estimated] |

### Automated (Block 2)

| Workflow | Avg Execution Time | Executions | Total Time |
|----------|-------------------|------------|------------|
| Workflow 1 | X min | N | X min |
| Workflow 2 | X min | N | X min |
| Workflow 3 | X min | N | X min |
| **Total** | | | **X min** |

### Time Saved

| Workflow | Manual | Automated | Savings/Exec | Executions | Total Saved |
|----------|--------|-----------|--------------|------------|-------------|
| WF1 | X min | X min | X min | N | X min |
| WF2 | X min | X min | X min | N | X min |
| WF3 | X min | X min | X min | N | X min |
| **Total** | | | | | **X hours** |

---

## Quality Metrics

### Quality Scores

| Workflow | Avg Score | Pass Rate | Review Rate | Revision Rate |
|----------|-----------|-----------|-------------|---------------|
| WF1 | X.X/5 | X% | X% | X% |
| WF2 | X.X/5 | X% | X% | X% |
| WF3 | X.X/5 | X% | X% | X% |
| **Average** | **X.X/5** | **X%** | **X%** | **X%** |

### Quality Observations
- [Notable patterns in quality scores]
- [Common reasons for review triggers]
- [Improvements observed over time]

---

## Cost Analysis

### Automation Costs

| Category | Amount | Notes |
|----------|--------|-------|
| AI API costs | $X.XX | [Claude API usage] |
| Platform costs | $X.XX | [Make/n8n tier] |
| Other costs | $X.XX | [If any] |
| **Total Cost** | **$X.XX** | |

### Value Created

| Metric | Calculation | Value |
|--------|-------------|-------|
| Time saved | X hours | |
| Hourly rate assumption | $150/hr | [Adjust if needed] |
| **Value of time saved** | X hours x $150 | **$X,XXX** |

### Return on Investment

| Metric | Value |
|--------|-------|
| Total value created | $X,XXX |
| Total cost | $X.XX |
| **Net value** | **$X,XXX** |
| **ROI** | **X,XXX%** |

---

## Annual Projection

### Based on Current Usage

| Metric | Calculation | Value |
|--------|-------------|-------|
| Current weekly rate | [X] executions/week | |
| Annual executions | X x 52 | [N] |
| Annual time saved | N x [avg savings] | [X] hours |
| Annual value | X hours x $150 | $[X,XXX] |
| Annual cost | $[X] x 12 months | $[X] |
| **Annual net value** | | **$[X,XXX]** |

### Team Scale Potential

If [X] team members used these workflows:
- Combined annual executions: [N] x [team size]
- Combined time saved: [X] hours x [team size]
- Combined value: $[X,XXX] x [team size] = **$[X,XXX]**

---

## Key Insights

### What Worked Well
1. [Insight 1]
2. [Insight 2]
3. [Insight 3]

### Areas for Improvement
1. [Area 1]
2. [Area 2]

### Recommendations
1. [Recommendation 1]
2. [Recommendation 2]

---

## Appendix: Raw Data

### Execution Log Summary
[Include key data points or link to detailed logs]

### Quality Score Details
[Include breakdown if available]
```

**Deliverables:**
- [ ] `block-2-impact-report.md` with real data
- [ ] All calculations documented with sources
- [ ] Committed to GitHub repository

---

### Exercise 7.3: Create Capstone Summary (10 minutes)

**Objective:** Prepare the cover document for your capstone submission

Create `block-2-capstone-summary.md` in your repository:

```markdown
# Block 2 Capstone Summary
## AI Workflow Toolkit

---

### Participant Information
- **Name:** [Your name]
- **Completion Date:** [Date]
- **Block 2 Duration:** [Start date] to [End date]

---

### Toolkit Contents

#### Workflows (3)

**1. [Workflow 1 Name]**
- **Purpose:** [What this workflow does]
- **Trigger:** [What initiates it]
- **Output:** [What it produces]
- **Integration:** [What systems it connects]
- **Documentation:** [Link to workflow docs]

**2. [Workflow 2 Name]**
- **Purpose:** [What this workflow does]
- **Trigger:** [What initiates it]
- **Output:** [What it produces]
- **Integration:** [What systems it connects]
- **Documentation:** [Link to workflow docs]

**3. [Workflow 3 Name]**
- **Purpose:** [What this workflow does]
- **Trigger:** [What initiates it]
- **Output:** [What it produces]
- **Integration:** [What systems it connects]
- **Documentation:** [Link to workflow docs]

#### Quality System
- **Evaluation prompts:** [Count] prompts
- **Quality rubrics:** [Count] rubrics
- **Quality gate threshold:** [Score]
- **Human review process:** [Brief description]
- **Location:** [Link to quality system docs]

#### MCP Implementation
- **Servers configured:** filesystem, GitHub
- **Integration points:** [Where MCP is used]
- **Documentation:** [Link to MCP docs]

#### Performance Monitoring
- **Logging system:** [Where logs are stored]
- **Metrics tracked:** [List of metrics]
- **Reports:** [Link to reports/dashboards]

---

### Impact Summary

| Metric | Value |
|--------|-------|
| Time saved (Block 2 period) | [X] hours |
| Quality improvement | [Description or %] |
| ROI achieved | [X]% |
| Annual value projection | $[X,XXX] |

---

### Key Achievements

1. **[Achievement 1]**
   - [Details]

2. **[Achievement 2]**
   - [Details]

3. **[Achievement 3]**
   - [Details]

---

### Lessons Learned

1. **[Learning 1]**
   - [What you learned and how it changed your approach]

2. **[Learning 2]**
   - [What you learned and how it changed your approach]

3. **[Learning 3]**
   - [What you learned and how it changed your approach]

---

### Block 3 Readiness

**How Block 2 prepares me for Block 3:**
- [Connection to AI agents]
- [Foundation elements that carry forward]

**What I want to build in Block 3:**
- [Goal or project idea]

---

### Repository Contents

| File/Folder | Description |
|-------------|-------------|
| `/workflows/` | Workflow documentation |
| `/templates/` | Prompt templates |
| `/rubrics/` | Quality rubrics |
| `/reports/` | Impact and performance reports |
| `integration-architecture.md` | System architecture |
| `block-2-impact-report.md` | Impact analysis |
| `block-2-capstone-summary.md` | This document |

**Repository URL:** [Your GitHub repository URL]

---

### Self-Evaluation Preview

*Complete self-evaluation in Week 8*

| Criterion | Preliminary Score | Evidence |
|-----------|-------------------|----------|
| 1. Workflow Design | /5 | |
| 2. Integration Quality | /5 | |
| 3. MCP Implementation | /5 | |
| 4. Quality Systems | /5 | |
| 5. Performance Monitoring | /5 | |
| 6. Documentation | /5 | |
| 7. Practical Application | /5 | |
| 8. Overall Value | /5 | |
| **Total** | **/40** | |
```

**Deliverables:**
- [ ] `block-2-capstone-summary.md` completed
- [ ] All links verified
- [ ] Committed to GitHub repository

---

## Reflection Questions

After completing this week's exercises, consider:

1. **Completeness:** Do you have all five required components?

2. **Quality:** Are you proud of what you've built?

3. **Impact:** What does your ROI calculation tell you about the value of AI automation?

4. **Documentation:** Could someone else understand and maintain your work?

5. **Readiness:** Are you prepared for self-evaluation next week?

---

## Key Takeaways

1. **Real data tells the story** - Actual metrics beat projections every time
2. **Documentation enables scaling** - Others can use and maintain your workflows
3. **ROI justifies investment** - Time savings have real monetary value
4. **Quality systems compound** - Better outputs improve over time
5. **Block 3 builds on Block 2** - Your workflows become agent building blocks

---

## Checklist Before Next Week

Before Week 8 (Capstone Evaluation), ensure:

- [ ] All 3 workflows finalized and tested
- [ ] Impact report complete with real data
- [ ] Capstone summary document created
- [ ] All documentation in GitHub repository
- [ ] Prepared to score yourself on 8 criteria
- [ ] Evidence ready for each self-evaluation score

---

## Resources

### Templates
- Impact report template (above)
- Capstone summary template (above)

### Tools
- [Draw.io](https://draw.io) - Architecture diagrams
- [Markdown Guide](https://www.markdownguide.org/) - Documentation formatting

### Support
- If you need help completing your capstone, reach out now
- Don't wait until Week 8 to ask for support

---

**Navigation:** [<- Week 6 Participant Guide](../week-6/participant-guide.md) | **Week 7** | [Week 8 Participant Guide ->](../week-8/participant-guide.md)
