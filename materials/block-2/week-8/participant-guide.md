# **PARTICIPANT GUIDE: BLOCK 2 WEEK 8**
## **Block 2 Capstone Evaluation**

**Block:** 2: AI Workflow Engineering
**Week:** 8 of 8 (Final Week)
**Week Type:** Self-paced evaluation (no live workshop)
**Theme Color:** Orange (Block 2)

---

## Navigation

**Block Navigation:** [<- Week 7 Participant Guide](../week-7/participant-guide.md) | **Week 8 (Final)** | [Block 3 Week 1 ->](../../block-3/week-1/participant-guide.md)

**Related Materials:**
- [Week 8 Presentation](presentation.md) (Summary slides)
- [Week 8 Instructor Guide](instructor-guide.md)
- [Block 2 Main Document](../block-2.md)

---

## Introduction

### This Is Evaluation Week

Week 8 has no live workshop. This week is dedicated to:
1. Finalizing your capstone submission
2. Completing self-evaluation
3. Submitting for certification

### Week 8 Timeline

| Day | Activity |
|-----|----------|
| Day 1-3 | Finalize all capstone materials |
| Day 4-5 | Complete self-evaluation |
| Day 5-6 | Submit everything |
| Day 6-7 | Receive feedback and certification |

---

## Submission Requirements

### What to Submit

1. **GitHub Repository Link**
   - Contains all workflow documentation
   - Includes prompt templates and rubrics
   - Has MCP configuration documentation
   - Contains performance logs/reports

2. **Impact Report**
   - `block-2-impact-report.md` with real data
   - Located in your GitHub repository

3. **Capstone Summary**
   - `block-2-capstone-summary.md`
   - Located in your GitHub repository

4. **Self-Evaluation (Optional but Encouraged)**
   - Completed rubric with scores
   - Evidence for each score
   - Reflection questions answered

### Submission Checklist

Before submitting, verify:

- [ ] GitHub repository is accessible (not private, or instructor has access)
- [ ] 3 workflows fully documented with architecture diagrams
- [ ] Quality evaluation prompts and rubrics included
- [ ] MCP configuration documented (tokens sanitized)
- [ ] Performance logs and analysis included
- [ ] Impact report with actual data complete
- [ ] Capstone summary complete
- [ ] All links in documents work correctly

---

## Self-Evaluation Process

### Block 2 Capstone Rubric

**Total Points: 40 (8 criteria x 5 points each)**

Complete the self-evaluation below. Be honest - accurate self-assessment is a valuable skill.

---

### Criterion 1: Workflow Design (5 points)

**Evaluates:** Architecture, efficiency, reliability, error handling

| Score | Description |
|-------|-------------|
| **5** | 3+ workflows with elegant architecture. Efficient step design. Comprehensive error handling. Parallel processing where appropriate. Clear triggering logic. Production-ready design. |
| **4** | 3 well-designed workflows. Good architecture. Solid error handling. Efficient in most areas. Minor design improvements possible. |
| **3** | 3 functional workflows. Basic architecture. Some error handling. Room for efficiency improvements. Mostly reliable. |
| **2** | Fewer than 3 workflows or poorly designed. Limited error handling. Inefficient execution. Unreliable in places. |
| **1** | Incomplete workflows or non-functional. No error handling. Poor design. |

**My Score:** ___/5

**Evidence:**
```
[Describe your workflows, architecture approach, and error handling]
```

---

### Criterion 2: Integration Quality (5 points)

**Evaluates:** Tool connections, data flow, seamless operation

| Score | Description |
|-------|-------------|
| **5** | Seamless integration across multiple tools. Clean data transformations. No manual intervention needed. Robust connections. Handles edge cases gracefully. |
| **4** | Good integration with most tools working smoothly. Minor data handling issues. Occasional manual steps. Generally reliable connections. |
| **3** | Basic integrations working. Some data transformation issues. Manual intervention sometimes needed. Connections work but fragile. |
| **2** | Limited integration. Frequent data issues. Regular manual intervention. Unreliable connections. |
| **1** | No meaningful integration. Disconnected components. Constant failures. |

**My Score:** ___/5

**Evidence:**
```
[Describe your integrations, data flows, and how tools connect]
```

---

### Criterion 3: MCP Implementation (5 points)

**Evaluates:** MCP configuration, server usage, practical application

| Score | Description |
|-------|-------------|
| **5** | Multiple MCP servers configured and actively used. GitHub integration with templates. Demonstrated practical value. Clear documentation. Security best practices followed. |
| **4** | MCP properly configured with 1-2 servers. Good practical use. Documentation present. Reasonable security. |
| **3** | Basic MCP configuration. At least one server working. Limited practical application. Basic documentation. |
| **2** | MCP attempted but limited success. Configuration issues. Minimal practical use. Poor documentation. |
| **1** | No MCP implementation or non-functional. |

**My Score:** ___/5

**Evidence:**
```
[Describe your MCP setup, servers configured, and how you use it]
```

---

### Criterion 4: Quality Systems (5 points)

**Evaluates:** Automated evaluation, quality gates, routing logic, human review

| Score | Description |
|-------|-------------|
| **5** | Comprehensive quality system. Automated evaluation with rubric-based scoring. Intelligent routing logic. Effective human review process. Feedback loop for improvement. Demonstrable quality gains. |
| **4** | Good quality system. Automated evaluation working. Clear routing logic. Human review when needed. Quality improvements visible. |
| **3** | Basic quality checks implemented. Some routing logic. Human review process exists. Limited quality measurement. |
| **2** | Minimal quality checking. Poor or missing routing. No systematic review process. Quality inconsistent. |
| **1** | No quality system implemented. No evaluation. No routing. |

**My Score:** ___/5

**Evidence:**
```
[Describe your quality system, evaluation approach, and routing logic]
```

---

### Criterion 5: Performance Monitoring (5 points)

**Evaluates:** Logging, metrics tracking, analysis, optimization

| Score | Description |
|-------|-------------|
| **5** | Comprehensive logging of all executions. Key metrics tracked (time, cost, quality, success rate). Regular analysis performed. Evidence of optimization based on data. Clear performance trends. |
| **4** | Good logging coverage. Most key metrics tracked. Some analysis done. Optimization attempted based on data. |
| **3** | Basic logging in place. Some metrics tracked. Limited analysis. Some awareness of performance. |
| **2** | Minimal logging. Few metrics. No analysis. No optimization. |
| **1** | No logging or performance tracking. |

**My Score:** ___/5

**Evidence:**
```
[Describe your logging, metrics tracked, and any optimization you did]
```

---

### Criterion 6: Documentation Completeness (5 points)

**Evaluates:** Architecture docs, setup guides, troubleshooting, examples

| Score | Description |
|-------|-------------|
| **5** | Comprehensive documentation for all workflows. Clear architecture diagrams. Detailed setup guides. Troubleshooting tips. Working examples. Someone else could set up from docs alone. |
| **4** | Good documentation coverage. Architecture documented. Setup instructions present. Some troubleshooting info. Examples included. |
| **3** | Basic documentation. Architecture partially documented. Setup instructions exist but incomplete. Limited troubleshooting. Few examples. |
| **2** | Minimal documentation. Missing architecture info. Incomplete setup. No troubleshooting. No examples. |
| **1** | No documentation or unusable. |

**My Score:** ___/5

**Evidence:**
```
[Describe your documentation, what's included, and its completeness]
```

---

### Criterion 7: Practical Application (5 points)

**Evaluates:** Real-world relevance, actual usage, business value

| Score | Description |
|-------|-------------|
| **5** | Workflows address real consulting needs. Evidence of actual use (20+ executions). Measurable time savings. Clear business value demonstrated. Team adoption potential high. |
| **4** | Workflows relevant to real work. Good usage evidence. Some time savings. Business value present. Could be adopted by team. |
| **3** | Workflows somewhat relevant. Limited actual usage. Theoretical value present. Adoption would require work. |
| **2** | Workflows not clearly relevant. Minimal usage. Questionable value. Not ready for team use. |
| **1** | No practical application demonstrated. |

**My Score:** ___/5

**Evidence:**
```
[Describe your real-world application, execution count, and measured value]
```

---

### Criterion 8: Overall Toolkit Value (5 points)

**Evaluates:** Completeness, coherence, impact, professionalism

| Score | Description |
|-------|-------------|
| **5** | Complete toolkit with all components. Coherent system that works together. Significant demonstrated impact. Professional presentation. Exceeds Block 2 requirements. Ready for Block 3. |
| **4** | All requirements met. Components work together. Good impact shown. Professional quality. Block 3 ready. |
| **3** | Most requirements met. Components function. Some impact shown. Acceptable quality. Can proceed to Block 3 with review. |
| **2** | Requirements partially met. Components don't integrate well. Limited impact. Quality issues. Block 3 readiness questionable. |
| **1** | Major requirements missing. Non-functional system. No impact. Not ready for Block 3. |

**My Score:** ___/5

**Evidence:**
```
[Describe your overall toolkit, how components work together, and total impact]
```

---

## Scoring Summary

| Criterion | My Score | Notes |
|-----------|----------|-------|
| 1. Workflow Design | /5 | |
| 2. Integration Quality | /5 | |
| 3. MCP Implementation | /5 | |
| 4. Quality Systems | /5 | |
| 5. Performance Monitoring | /5 | |
| 6. Documentation Completeness | /5 | |
| 7. Practical Application | /5 | |
| 8. Overall Toolkit Value | /5 | |
| **TOTAL** | **/40** | |

---

## Performance Levels

| Score Range | Level | What It Means |
|-------------|-------|---------------|
| 34-40 | **Excellent** | Exceptional work. Fully prepared for Block 3. Toolkit ready for team use. |
| 28-33 | **Good** | Strong work. Ready for Block 3. Minor enhancements would elevate to excellent. |
| 22-27 | **Adequate** | Acceptable work. Can proceed to Block 3 with commitment to address gaps. |
| 16-21 | **Needs Improvement** | Significant gaps. Additional work needed before Block 3. |
| 0-15 | **Incomplete** | Major elements missing. Not ready for Block 3. |

**Certification requires 22+ points.**

---

## Reflection Questions

Answer these as part of your self-evaluation:

### 1. Production Readiness

> Are my workflows production-ready?

- Would I trust them to run without supervision?
- Have I tested edge cases and errors?
- Is monitoring in place?

**My Answer:**
```
[Your reflection]
```

### 2. Quality Impact

> Does my quality system actually improve output?

- Can I show before/after quality metrics?
- Is human review systematic and efficient?
- Do I learn from failures?

**My Answer:**
```
[Your reflection]
```

### 3. MCP Value

> Is MCP adding real value?

- Am I using it for practical purposes?
- Is it integrated into workflows?
- Could I demonstrate it to my team?

**My Answer:**
```
[Your reflection]
```

### 4. Actual Impact

> What's my actual impact?

- Real time saved (not theoretical)
- Real quality improvement
- Real cost analysis

**My Answer:**
```
[Your reflection]
```

### 5. Lessons Learned

> What would I do differently?

- In workflow design?
- In tool selection?
- In quality systems?
- What lessons will I carry to Block 3?

**My Answer:**
```
[Your reflection]
```

---

## What You've Achieved (Block 2)

By completing Block 2, you have demonstrated:

- **Workflow Design** - Ability to architect multi-step AI automations
- **Tool Integration** - Connecting platforms, APIs, and outputs
- **MCP Proficiency** - Configuring AI tool access
- **Quality Systems** - Building automated evaluation and routing
- **Performance Monitoring** - Tracking and optimizing execution
- **Documentation** - Creating maintainable, handoff-ready materials
- **Impact Measurement** - Quantifying business value

---

## What's Coming (Block 3)

### Block 3: AI Automation Architecture

**You Will Build:**
- Reliable AI agents with guardrails
- Multi-agent orchestration patterns
- Production deployment systems
- Team-scale AI workflows

**The Progression:**

| Block | Focus | What You Build |
|-------|-------|----------------|
| Block 1 | Prompt Engineering | The AI brain |
| Block 2 | Workflow Automation | The AI body |
| Block 3 | Agent Architecture | Autonomous systems |

### Your Workflows Become Agent Building Blocks

Everything you built in Block 2 carries forward:
- Workflows become components agents orchestrate
- MCP becomes how agents access tools
- Quality systems become agent guardrails
- Monitoring becomes agent supervision

---

## Certification

### Upon Successful Completion (22+ points)

**You Have Demonstrated:**
- Ability to design and build multi-step AI workflows
- Proficiency in MCP configuration and tool integration
- Understanding of quality systems and automated evaluation
- Skill in performance monitoring and optimization
- Creation of reusable workflow templates for team use
- Measured business impact with actual data

**You Are Certified As:** AI Workflow Engineer

### Next Steps After Certification

1. **Receive feedback** from instructor
2. **Enroll in Block 3** (AI Automation Architecture)
3. **Review Block 2-to-3 checkpoint** materials
4. **Continue using** your workflows and improving them

---

## Final Submission Checklist

Before you submit, confirm:

**Repository Contents:**
- [ ] All workflow documentation complete
- [ ] Architecture diagrams for each workflow
- [ ] Quality evaluation prompts included
- [ ] Quality rubrics included
- [ ] MCP configuration documented
- [ ] Performance logs included
- [ ] Integration architecture document present

**Required Documents:**
- [ ] `block-2-impact-report.md` with real data
- [ ] `block-2-capstone-summary.md` complete
- [ ] All links work correctly

**Self-Evaluation:**
- [ ] All 8 criteria scored
- [ ] Evidence provided for each score
- [ ] Reflection questions answered

**Final Check:**
- [ ] Repository is accessible (not private)
- [ ] All files are committed
- [ ] Ready to submit

---

## How to Submit

1. **Verify all materials** using the checklist above
2. **Commit final changes** to your GitHub repository
3. **Submit your repository link** via [submission method]
4. **Include your self-evaluation** (if completing)

---

## Congratulations!

You've completed Block 2: AI Workflow Engineering.

You started with individual AI interactions. Now you have:
- 3 working, integrated workflows
- Quality systems with automated evaluation
- MCP servers for tool access
- Performance monitoring and optimization
- A documented, reusable toolkit
- Measured business impact

This toolkit will continue to save time and improve quality. And you're now ready to build autonomous AI agents in Block 3.

**Well done!**

---

**Navigation:** [<- Week 7 Participant Guide](../week-7/participant-guide.md) | **Week 8 (Final)** | [Block 3 Week 1 ->](../../block-3/week-1/participant-guide.md)
