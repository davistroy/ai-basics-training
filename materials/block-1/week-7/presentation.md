# **POWERPOINT PRESENTATION: BLOCK 1 WEEK 7**
## **Block 1 Capstone Preparation**

**Block:** 1: AI Prompting Mastery
**Week Number:** 7
**Session Duration:** 45 minutes
**Delivery Format:** Live MS Teams workshop

**Target Audience:** Participants preparing for Block 1 capstone evaluation

**Key Thesis:** Completion is not perfection—the capstone evaluates practical application and systematic thinking, not flawless execution, making thoughtful documentation of your learning journey as valuable as the templates themselves.

**Week Learning Objectives:** By the end of this session, participants will:
1. Understand all capstone requirements
2. Know the quality bar for templates
3. Create a task priority matrix
4. Finalize `style.json`

**Entry Criteria:**
- [ ] Week 6 exercises completed
- [ ] At least 5 templates created
- [ ] `style.json` exists
- [ ] Repository organized

**Exit Criteria:**
- [ ] Clear on capstone requirements
- [ ] Knows gaps to fill
- [ ] Has plan for Week 7 exercises
- [ ] Ready for Week 8 self-evaluation

**Presentation Structure:**
1. Opening & Recap (5 min) - Slides 1-3
2. Segment 1: Capstone Requirements (10 min) - Slides 4-6
3. Segment 2: Template Completion (10 min) - Slides 7-9
4. Segment 3: Task Priority Matrix (12 min) - Slides 10-12
5. Segment 4: Final Prep + Close (8 min) - Slides 13-15

**Total Slides:** 15

---

## Slide Definitions

### SLIDE 1: TITLE SLIDE

**Title:** Block 1 Week 7: Capstone Preparation

**Subtitle:** Your Final Preparation

**Content:**
- AI Practitioner Training Program
- Block 1: AI Prompting Mastery
- Week 7 of 8

**Graphic:** Clean title slide with blue color scheme (Block 1 theme).

**SPEAKER NOTES:**

"Welcome to Week 7 - our final instructional session for Block 1.

Over the past six weeks, you've learned prompting techniques, built templates, created quality systems, and organized your library.

This week is about completion. Making sure you have everything ready for the capstone evaluation.

Week 8 is self-evaluation - no live workshop. So today, let's make sure you're fully prepared."

[Transition]

---

### SLIDE 2: WEEK OVERVIEW

**Title:** This Week's Journey

**Content:**

| Time | Topic | Focus |
|------|-------|-------|
| 0-5 min | Opening | Week 6 Recap |
| 5-15 min | Segment 1 | Capstone Requirements |
| 15-25 min | Segment 2 | Template Completion |
| 25-37 min | Segment 3 | Task Priority Matrix |
| 37-45 min | Segment 4 | Final Prep + Close |

**Graphic:** Timeline with capstone icons

**SPEAKER NOTES:**

"Here's our agenda:

First, capstone requirements - exactly what you need to submit.

Then template completion - the quality bar for each template.

Task priority matrix - strategic thinking about AI automation.

Final preparation and homework to complete before Week 8."

[Transition]

---

### SLIDE 3: WEEK 6 RECAP

**Title:** Quick Recap: Organization

**Content:**

**Taxonomy:**
- Categories matching your mental model
- Max 3 levels deep

**Naming Conventions:**
- [type]-[specificity]-[variant].md
- Consistent, predictable

**Metadata & Index:**
- Headers enable search
- Index is single source of truth

**The Question:**
Is your library capstone-ready?

**Graphic:** Organization icons from Week 6

**SPEAKER NOTES:**

"Last week you organized your library. Taxonomy, naming conventions, metadata, index.

[Point to question]

The question now: Is it capstone-ready?

Let's review exactly what's required."

[Transition]

---

## SEGMENT 1: CAPSTONE REQUIREMENTS
### Duration: 10 minutes | Slides 4-6

---

### SLIDE 4: CAPSTONE COMPONENTS

**Title:** Block 1 Capstone: What's Required

**Content:**

**Five Required Components:**

| Component | Requirement |
|-----------|-------------|
| **GitHub Repository** | Organized, documented |
| **Prompt Templates** | 5+ documented, tested |
| **`style.json`** | Complete, tested |
| **Quality Rubrics** | 2+ with specific criteria |
| **Task Priority Matrix** | Analysis of AI opportunities |

**Self-Check:**
Which of these do you have completed right now?

**Graphic:** Five component icons with checkboxes

**SPEAKER NOTES:**

"Five components are required for the capstone.

[Walk through components]

GitHub repository - organized with documentation.

Prompt templates - at least 5, fully documented and tested.

`style.json` - complete configuration, tested.

Quality rubrics - at least 2, with specific criteria.

Task priority matrix - analysis of your automation opportunities.

[Point to self-check]

Be honest: which of these do you have completed right now? Which need work?"

[Transition]

---

### SLIDE 5: EVALUATION CRITERIA

**Title:** How You'll Be Evaluated

**Content:**

**Six Dimensions (5 points each):**

| # | Criterion | What It Measures |
|---|-----------|------------------|
| 1 | Template Quality | Complete documentation |
| 2 | Variety & Coverage | Different use cases |
| 3 | `style.json` | Comprehensive, tested |
| 4 | Quality Systems | Specific rubrics |
| 5 | Repository Org | Easy to find things |
| 6 | Practical Application | Evidence of real use |

**Total: 30 points**

**Graphic:** Six criteria with point values

**SPEAKER NOTES:**

"You'll be evaluated on six dimensions, 5 points each.

[Walk through criteria]

Template quality - are templates fully documented?
Variety - do you cover different deliverable types?
`style.json` - is it comprehensive and tested?
Quality systems - are rubrics specific, not vague?
Repository organization - can someone find things?
Practical application - is there evidence of real use?

Total of 30 points possible."

[Transition]

**BACKGROUND:**

**Rationale:**
- Makes evaluation transparent and reduces anxiety about "will I pass?"
- Six dimensions provide clear action items participants can verify before submission
- Equal weighting (5 points each) signals that all dimensions matter equally
- The "what it measures" column clarifies the intent behind each criterion, preventing misinterpretation

**Key Research & Citations:**
- **Transparent Assessment Research (Educational Psychology)**: Studies show that when learners understand evaluation criteria upfront, performance improves by 20-30% compared to opaque assessment. Transparency reduces anxiety and enables self-directed improvement.
- **Rubric Design Principles**: Breaking total score into multiple weighted criteria provides more actionable feedback than single holistic score. If someone scores low on "repository organization" but high elsewhere, they know exactly what to improve.
- **Formative Assessment Theory**: The capstone is summative (final evaluation), but presenting criteria in Week 7 makes it formative—participants have one week to address gaps. This improves both scores and actual learning.

**Q&A Preparation:**
- *"Can I see example capstones from previous cohorts?"*: We don't provide examples to avoid template copying. The rubric defines quality—your work should reflect YOUR tasks and preferences, not someone else's. Authentic work scores better than imitation.
- *"What if I'm strong in some areas but weak in others?"*: That's normal and expected. The 60% passing threshold (18/30) allows for varied strengths. Focus effort on your weakest criterion—raising a 2 to a 4 (+2 points) is easier than raising a 4 to a 5 (+1 point).
- *"How strict is the grading?"*: Grading is criterion-referenced, not norm-referenced. If your work meets the criterion description for "4", you get 4 points regardless of how others perform. Quality standards are fixed, not curved.

---

### SLIDE 6: SCORING AND LEVELS

**Title:** Scoring Guide

**Content:**

**Performance Levels:**

| Score | Percentage | Level | Meaning |
|-------|------------|-------|---------|
| 26-30 | 87-100% | Excellent | Exceptional work |
| 22-25 | 73-86% | Good | Solid, ready for Block 2 |
| 18-21 | 60-72% | Adequate | Meets requirements |
| Below 18 | Below 60% | Not Passing | Needs improvement |

**Passing Score: 18 points (60%)**

**If Not Passing:**
- Review feedback
- Address gaps
- Resubmit

**Graphic:** Score ranges with indicators

**SPEAKER NOTES:**

"Here are the performance levels.

[Walk through levels]

26-30 is Excellent - exceptional work, strong foundation for Block 2.

22-25 is Good - solid work, ready for Block 2 with minor refinements.

18-21 is Adequate - meets requirements, certified but some gaps to address.

Below 18 - not passing. You'd review feedback, address gaps, and resubmit.

Passing is 18 points - 60%. That's achievable if you complete all components with reasonable quality."

[Transition]

---

## SEGMENT 2: TEMPLATE COMPLETION
### Duration: 10 minutes | Slides 7-9

---

### SLIDE 7: WHAT EACH TEMPLATE NEEDS

**Title:** Template Completion Checklist

**Content:**

**Required Sections:**
- [ ] Metadata header (title, category, tags, version)
- [ ] Purpose (2-3 sentences)
- [ ] When to use (scenarios)
- [ ] Template with marked [VARIABLES]
- [ ] Variable descriptions table
- [ ] Real example (input AND output)
- [ ] Tips for best results
- [ ] Quality rubric reference

**Key Requirement:**
Examples must be REAL - actual AI outputs, not placeholders.

**Graphic:** Checklist with sections highlighted

**SPEAKER NOTES:**

"Every template needs these sections.

[Walk through list]

Metadata header for searchability.
Purpose explaining what it does.
When to use with specific scenarios.
The actual template with variables marked.
Variable descriptions in a table.
A real example showing input and output.
Tips from your experience.
Connection to a quality rubric.

[Point to key requirement]

The example must be real. Actual AI output from testing the template. Not placeholder text."

[Transition]

---

### SLIDE 8: QUALITY CHECK QUESTIONS

**Title:** Template Quality Self-Check

**Content:**

**Ask yourself:**

1. **Purpose:** Could someone understand what this does in 10 seconds?

2. **Variables:** Are all placeholders explained?

3. **Example:** Is this a REAL AI response, not a made-up one?

4. **Testing:** Have you actually used this template?

5. **Rubric:** Does this connect to quality evaluation?

**The Test:**
Could someone else use this template without asking you any questions?

**Graphic:** Question icons

**SPEAKER NOTES:**

"Quality check yourself with these questions.

[Walk through questions]

Purpose - can someone understand it in 10 seconds?
Variables - are all placeholders explained?
Example - is it real, not made up?
Testing - have you actually used it?
Rubric - is there a quality connection?

[Point to test]

The ultimate test: Could someone else use this template without asking you anything? If the answer is no, add more documentation."

[Transition]

---

### SLIDE 9: TEMPLATE AUDIT

**Title:** Audit Your Templates Now

**Content:**

**Create this audit:**

| Template | Purpose? | Vars? | Example? | Rubric? | Complete? |
|----------|----------|-------|----------|---------|-----------|
| [Name] | ✓/✗ | ✓/✗ | ✓/✗ | ✓/✗ | ✓/✗ |
| [Name] | ✓/✗ | ✓/✗ | ✓/✗ | ✓/✗ | ✓/✗ |

**Requirements:**
- Minimum 5 complete templates
- Variety of deliverable types preferred
- Quality > Quantity

**Action:**
Fill gaps this week. Exercise 7.1.

**Graphic:** Audit table example

**SPEAKER NOTES:**

"Take a moment to mentally audit your templates.

[Point to table]

For each template: does it have purpose, variables, example, rubric connection?

How many are truly complete?

[Point to requirements]

You need at least 5. Variety is good - different deliverable types show broader capability.

But remember: quality over quantity. 5 excellent templates beat 10 mediocre ones.

Your Exercise 7.1 this week is completing this audit and filling gaps."

[Transition]

---

## SEGMENT 3: TASK PRIORITY MATRIX
### Duration: 12 minutes | Slides 10-12

---

### SLIDE 10: WHAT IS THE TASK MATRIX

**Title:** Task Priority Matrix: Strategic Thinking

**Content:**

**Purpose:**
Identify your highest-value AI automation opportunities.

**The Matrix:**
```
        │ Low Time    │ High Time
───────────────────────────────────
High    │ Quick Wins  │ Automate First
Freq    │             │
───────────────────────────────────
Low     │ Optional    │ Worth
Freq    │             │ Automating
```

**Score = Frequency x Time Impact**
- Frequency: How often? (1-5)
- Time: How long? (1-5)

**Graphic:** 2x2 matrix with quadrants labeled

**SPEAKER NOTES:**

"The task priority matrix shows strategic thinking about AI automation.

[Explain concept]

You rate tasks on two dimensions: how often do you do this task, and how long does it take.

Multiply for a score.

[Point to matrix]

High frequency, high time - automate first. These are your biggest opportunities.

High frequency, low time - quick wins. Easy to automate, cumulative value.

Low frequency, high time - worth automating when they come up.

Low frequency, low time - optional. Don't bother unless it's easy."

[Transition]

**BACKGROUND:**

**Rationale:**
- Introduces strategic thinking tool that connects Block 1 skills to real-world ROI
- The 2x2 matrix is familiar from business strategy frameworks (Eisenhower Matrix, BCG Matrix), making it immediately accessible
- Quantifying automation opportunity (frequency × time) converts subjective "this seems tedious" into objective prioritization
- This positions Block 1 as strategic investment, not just skill acquisition—elevates participant perspective

**Key Research & Citations:**
- **Eisenhower Matrix / Priority Matrix Theory**: The frequency-vs-time matrix is variant of urgent-important prioritization. Research shows that explicitly scoring and plotting tasks increases follow-through on high-value activities by 40-50% versus informal prioritization.
- **ROI Calculation for Automation**: Formula is: (Time saved per instance × Frequency per year) × (Years of use). A 30-minute weekly task saved for 2 years = 52 hours. Even 10 hours to automate yields 5:1 ROI.
- **Automation Opportunity Research (McKinsey)**: Studies show that 60-70% of automation value comes from 20-30% of use cases. The task matrix identifies that high-value 20%—not everything should be automated, but the right things should.

**Q&A Preparation:**
- *"How do I estimate frequency and time accurately?"*: Don't overthink precision. Use ranges: 1=rare, 3=weekly, 5=daily. 1=minutes, 3=30min-hour, 5=multi-hour. Rough estimates are sufficient for prioritization—you're finding the 25s (high-high), not precisely ranking 12 vs 15.
- *"What if I don't have templates for my highest-scoring tasks yet?"*: Perfect—that identifies your biggest opportunity. Those become your next templates to build. The matrix shows where effort yields maximum return.
- *"Isn't this just for my own work? How does it help the capstone?"*: The matrix demonstrates practical application (#6 criterion). It shows you're not randomly making templates—you're strategically targeting high-value automation opportunities. That's practitioner-level thinking.

---

### SLIDE 11: CREATING YOUR MATRIX

**Title:** Building Your Matrix

**Content:**

**Step 1: List tasks (10+ recommended)**
- Communication tasks
- Analysis tasks
- Content creation
- Administrative work
- Tasks you avoid

**Step 2: Rate each task**
- Frequency (1-5)
- Time Impact (1-5)
- Calculate score

**Step 3: Sort into quadrants**
- Identify patterns
- Note which have templates

**Step 4: Action plan**
- Gaps to fill for Block 1
- Candidates for Block 2

**Graphic:** Process steps

**SPEAKER NOTES:**

"Here's how to create your matrix.

[Walk through steps]

First, list tasks. Think through a typical week. What do you do repeatedly? What's tedious? Aim for at least 10 tasks.

Second, rate each. Frequency 1-5, time impact 1-5, multiply.

Third, sort into quadrants. Which tasks fall where? Note which ones already have templates.

Fourth, create your action plan. What gaps should you fill this week? What tasks are too complex for templates and need Block 2 workflow automation?"

[Transition]

---

### SLIDE 12: STRATEGIC VALUE

**Title:** Why This Matters

**Content:**

**Block 1 Value:**
- Shows you're not just making templates randomly
- Identifies gaps in your library
- Prioritizes what to build next

**Block 2 Connection:**
- High-score tasks without templates = Block 2 candidates
- Complex workflows need automation, not just prompts
- Your matrix becomes your Block 2 roadmap

**Evaluation:**
This is criterion #6: Practical Application
- Shows strategic thinking
- Evidence you're applying skills

**Graphic:** Connection diagram to Block 2

**SPEAKER NOTES:**

"Why does this matter?

[Point to Block 1 value]

For Block 1, it shows strategic thinking. You're not making random templates - you're targeting high-value opportunities.

[Point to Block 2 connection]

For Block 2, your matrix becomes a roadmap. Tasks that need automation beyond simple prompts are workflow candidates.

[Point to evaluation]

This directly feeds criterion #6 - practical application. Evaluators want to see you're thinking strategically about where AI adds value."

[Transition]

---

## SEGMENT 4: FINAL PREP + CLOSE
### Duration: 8 minutes | Slides 13-15

---

### SLIDE 13: STYLE.JSON FINALIZATION

**Title:** Finalizing Your `style.json`

**Content:**

**Completion Checklist:**
- [ ] Metadata (version, date, author)
- [ ] Voice (tone, formality, personality)
- [ ] Writing (sentence length, paragraph length)
- [ ] Preferences (always use, always avoid)
- [ ] Formatting (headers, lists, emphasis)
- [ ] Domain-specific (your field)

**Testing Requirement:**
Used in 5+ prompts with verified results.

**Documentation:**
Usage guide explaining how to use it.

**Graphic:** `style.json` structure

**SPEAKER NOTES:**

"`style.json` needs to be finalized this week.

[Walk through checklist]

All sections should be complete and reflect YOUR actual preferences.

[Point to testing]

You need to have tested it with at least 5 prompts. Does AI follow your preferences?

[Point to documentation]

Create a usage guide explaining how to use your `style.json` in prompts."

[Transition]

---

### SLIDE 14: HOMEWORK OVERVIEW

**Title:** This Week's Exercises

**Content:**

| Exercise | Focus | Deliverable |
|----------|-------|-------------|
| 7.1 | Template completion | All templates documented |
| 7.2 | Task priority matrix | `task-priority-matrix.md` |
| 7.3 | `style.json` finalization | Complete, tested |
| 7.4 | Repository review | Capstone summary |

**Critical Reminder:**
Week 8 is self-evaluation. No live workshop.

**Submit by end of Week 8:**
- Repository link
- Capstone summary
- Self-evaluation

**Graphic:** Exercise cards

**SPEAKER NOTES:**

"Four exercises this week.

Exercise 7.1 - complete all template documentation.
Exercise 7.2 - create your task priority matrix.
Exercise 7.3 - finalize `style.json` with testing.
Exercise 7.4 - comprehensive repository review and capstone summary.

[Point to critical reminder]

Critical: Week 8 has NO live workshop. It's self-evaluation week.

You'll submit your repository link, capstone summary, and complete self-evaluation using the rubric."

[Transition]

---

### SLIDE 15: WEEK 8 PREVIEW

**Title:** Week 8: Evaluation Week

**Content:**

**What Happens:**
- No live workshop
- Complete self-evaluation using rubric
- Submit capstone materials
- Results within 1 week

**What to Submit:**
1. GitHub repository link
2. Capstone summary document
3. Self-evaluation scores

**After Passing:**
- **Certified as:** AI Prompting Practitioner
- **Next:** Eligible for Block 2 enrollment

**Graphic:** Certification badge preview

**SPEAKER NOTES:**

"Week 8 is evaluation week.

[Walk through what happens]

No live workshop. You complete self-evaluation, submit your materials, and get results within a week.

[Point to what to submit]

Submit repository link, capstone summary, and your self-evaluation.

[Point to after passing]

When you pass, you're certified as AI Prompting Practitioner. You're eligible for Block 2 - AI Workflow Engineering.

This is the end of our instructional time together for Block 1. You have the skills and the framework. This week is about completion.

Questions before we wrap?

[Take questions]

Congratulations on reaching Week 7. Finish strong. See your results next week."

---

## APPENDICES

### APPENDIX A: Slide Type Definitions

(See Week 1 presentation for complete slide type reference - consistent across all weeks)

Key slide types used in Week 7:
- **FRAMEWORK / MODEL**: Capstone components (Slide 4)
- **ASSESSMENT**: Evaluation criteria (Slide 5)
- **SCORING GUIDE**: Performance levels (Slide 6)
- **CHECKLIST**: Template completion (Slide 7)
- **STRATEGIC TOOL**: Task priority matrix (Slides 10-12)

---

### APPENDIX B: Content Element Formats

(Standard formatting conventions apply - see Week 1 for complete reference)

---

### APPENDIX C: Speaker Notes Conventions

(Standard stage directions and transitions - see Week 1 for complete reference)

---

### APPENDIX D: Background Section Guidelines

**Rationale (3-5 bullets)**
- Explain the slide's purpose in the narrative arc

**Key Research & Citations (3-5 entries)**
Format: **[Source Name (Year)]**: [Detailed explanation]

**Q&A Preparation (3-5 questions)**
Format: *"[Question]"*: [Response]

---

### APPENDIX E: Visual Design Guidelines

**Block 1 Color Coding**
- **Primary color**: Blue (completion and achievement theme)
- See Week 1 for complete visual design guidelines

---

### APPENDIX F: Quality Checklist

**Content Quality**
- [ ] Slide type clearly identified
- [ ] Key Thesis established in metadata
- [ ] Capstone requirements are clear

**Week 7 Specific**
- [ ] Capstone components clearly listed
- [ ] Evaluation criteria explained with point values
- [ ] Scoring guide shows all performance levels
- [ ] Task priority matrix instructions are complete
- [ ] Completion focus emphasized over perfection

---

## Version History

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 2.0 | 2026-01-03 | Enhanced with Key Thesis and expanded appendices | Claude |
| 1.0 | 2025-01-01 | Initial presentation created | Training Team |
